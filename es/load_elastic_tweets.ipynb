{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from random import randrange\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "CLOUD_ID = \"\"\n",
    "USER = \"elastic\"\n",
    "PASSWORD = \"\"\n",
    "INDEX = \"tweets\"\n",
    "\n",
    "MAPPING = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"country\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"location\": {\n",
    "                \"type\": \"geo_point\",\n",
    "                \"ignore_malformed\": \"true\"\n",
    "            },\n",
    "            \"sourceapp\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"user\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"hashtags\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"created_at\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"text\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"@timestamp\": {\n",
    "                \"format\": \"dateOptionalTime\",\n",
    "                \"type\": \"date\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es = Elasticsearch(\n",
    "    cloud_id=CLOUD_ID,\n",
    "    http_auth=(USER, PASSWORD),\n",
    "    http_compress=True\n",
    ")\n",
    "\n",
    "es.indices.delete(INDEX, ignore_unavailable=True)\n",
    "\n",
    "es.indices.create(INDEX, body=MAPPING)\n",
    "\n",
    "data_path = \"../data/tweets.ndjson.zip\"\n",
    "bulk_data = []\n",
    "ix = 0\n",
    "total = 0\n",
    "\n",
    "with zipfile.ZipFile(data_path) as zipped_data:\n",
    "    for f in zipped_data.namelist():\n",
    "        with zipped_data.open(f) as ndjson:\n",
    "            for line in ndjson.readlines():\n",
    "                data = json.loads(line.decode(\"utf-8\"))\n",
    "                bulk_data.append({\"index\": {\"_index\": INDEX, \"_id\": data[\"id\"]}})\n",
    "                bulk_data.append(data)\n",
    "                ix = ix + 1\n",
    "                total = total + 1\n",
    "                \n",
    "                if ix == 1000:             \n",
    "                    es.bulk(bulk_data)\n",
    "                    ix = 0\n",
    "                    bulk_data = []\n",
    "                    \n",
    "                    if randrange(0, 5000, 1) % 5 == 0:\n",
    "                        try:\n",
    "                            indexed = es.count(index=INDEX)[\"count\"]\n",
    "                            print(\"Indexado hasta el momento: {indexed}\".format(indexed=indexed))\n",
    "                        except:\n",
    "                            pass\n",
    "    if ix > 0:\n",
    "        es.bulk(bulk_data)\n",
    "        ix = 0\n",
    "        bulk_data = []\n",
    "\n",
    "print(\"Documentos indexados: {total}\".format(total=total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
